{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Life Sized Fruit Ninja",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [Click here for workshop instructions](https://msu-ai.notion.site/Workshop-Instructions-06d5c272f263455a97ec9795ff1c7704)"
      ],
      "metadata": {
        "id": "EoAerL45lKu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load an image\n",
        "Before we can do any pose estimation, we need an image of a person. Run the following command to download a photo of MSU's own Tom Izzo:"
      ],
      "metadata": {
        "id": "DT4yy6Kyjr2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZI_pP1VjZnT"
      },
      "outputs": [],
      "source": [
        "!curl -o tom-izzo.webp 'https://cdn.vox-cdn.com/thumbor/-5PVeiyaxPciGcZFfS21PkNxbwQ=/0x0:4152x2880/1820x1213/filters:focal(1762x144:2426x808):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/63298666/usa_today_12318130.0.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the above command, the file `tom-izzo.webp` should exist in the files tab on the left. Let's use some python code to display it. You'll need to update this code to make it read the file:"
      ],
      "metadata": {
        "id": "6TlENFDBlJqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image:\n",
        "# (Do you remember how to read an image file?\n",
        "# Consult last week's instructions if you need help.)\n",
        "image = # ???\n",
        "\n",
        "# Convert it to RGB form because that's what every other package uses\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "C-Vj55l3lU0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Perform pose estimation\n",
        "Amazing! Now we want to look at the image of Tom and determine where all his limbs are. This is called pose estimation, and luckily for us, there's a python library called [mediapipe](https://google.github.io/mediapipe/solutions/pose.html) that can really come in handy. Mediapipe is made by Google, and it contains many pre-trained neural networks for performing all kinds of computer vision tasks.\n",
        "\n",
        "Run the following command to install the mediapipe package:"
      ],
      "metadata": {
        "id": "Z5qJ6tialwXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mediapipe"
      ],
      "metadata": {
        "id": "gMgr_knZmj3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now that mediapipe is installed, let's use it to compute Tom's pose and display the results. **The following code to compute Tom's pose has a bug. Can you fix it?**"
      ],
      "metadata": {
        "id": "Vv_9b8-Vmmve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image and convert to RGB format\n",
        "image = cv2.imread(\"tom-izzo.webp\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Compute the pose\n",
        "pose = mp.solutions.pose.Pose()\n",
        "results = pose.process(img)\n",
        "\n",
        "# Draw the pose on the image\n",
        "mp.solutions.drawing_utils.draw_landmarks(\n",
        "    image,\n",
        "    results.pose_landmarks,\n",
        "    mp.solutions.pose.POSE_CONNECTIONS\n",
        ")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "VcOKl6zlmXrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazing! If all went well, you should see lines drawn on Tom Izzo's body indicating his pose.\n",
        "\n",
        "As you can see, mediapipe has done a lot of heavy lifting for us. We created a `pose` object and asked it to process our image, and it gave us some `results` (in the form of cryptic numbers). Then, mediapipe even helped us draw the results onto the image so we can see what the computer is thinking!"
      ],
      "metadata": {
        "id": "gNUT1Jvhni_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Understand the results\n",
        "Just drawing the results isn't enough. If we really want to do anything useful, we need cold, hard numbers. So it's time to dive into the `results` ourselves.\n",
        "\n",
        "Run this line of code to investigate the `results` variable that we computed above:"
      ],
      "metadata": {
        "id": "OiH-Crqxohld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "-a4P-QhAoSJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hmm... ðŸ¤”** This isn't helpful at all. The print statement is just telling us that we have an instance of the class SolutionOutputs. We need to dive deeper.\n",
        "\n",
        "In the code before, we used `results.pose_landmarks`. Try editing the following to print out `results.pose_landmarks` so we can take a look inside:"
      ],
      "metadata": {
        "id": "g5p7iRDdox0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print() # Edit me"
      ],
      "metadata": {
        "id": "V986gh1zpEfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aha!** This is much better. `pose_landmarks` is a big list of landmark points on the image. As you can see, there are many landmarks, and each landmark has an x, y, z, and visibility.\n",
        "\n",
        "To understand what these mean, take a look at the following diagram, provided by mediapipe:\n",
        "\n",
        "![Pose landmark map](https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png)\n",
        "\n",
        "As you can see, each \"landmark\" (special point) on the body is assigned a number. The nose is number 0, the right thumb is number 22, and so on. `results.pose_landmarks` contains these landmarks in order.\n",
        "\n",
        "Strangely, `results.pose_landmarks` is an object, and to get the actual list, you have to write `results.pose_landmarks.landmark`. So if you want to get the location of the left eye (which is landmark number 2), you would write `results.pose_landmarks.landmark[2]`.\n",
        "\n",
        "Try printing out the location of Tom Izzo's left wrist landmark:"
      ],
      "metadata": {
        "id": "bWs-0GAtpUCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print() # Edit me"
      ],
      "metadata": {
        "id": "C-gSwENCtgM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get `x: 0.66499` and `y: 0.78431`. Do these numbers make sense? Let's check back in on the image of Tom we generated earlier:"
      ],
      "metadata": {
        "id": "KpfQbPt-uANn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image we generated earlier of Tom and his pose\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "ADf2qrk2uNpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmmm... Since we're facing Tom, his left wrist is actually the hand on the right side of the picture. So based on the coordinates shown, it seems like his wrist has `x: 1250` and `y: 950` (give or take). But that's not what was computed!\n",
        "\n",
        "**Question:** Why `x: 0.66499` and `y: 0.78431`?"
      ],
      "metadata": {
        "id": "tIQICshdujXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Convert the results to useful coordinates\n",
        "\n",
        "Hopefully you've taken a moment to think about the previous question. What you might have noticed is that these decimal values are sort of like percentages across the width and height of the image. Tom's left wrist is indeed about 66.4% of the way from left to right (so a bit right of center) and about 78.4% from top to bottom (so pretty close to the bottom of the image).\n",
        "\n",
        "This percentage format is cute, but it isn't very helpful to us. To do anything useful, we need to convert it to the standard pixel coordinates.\n",
        "\n",
        "Your job is to write a function to do just that. (Hint: You'll need to use `image.shape`.)"
      ],
      "metadata": {
        "id": "_E39IFVhwtyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your job is to complete the toPixelCoordinates function\n",
        "# To convert x and y from decimals to pixel numbers\n",
        "\n",
        "def toPixelCoordinates(x, y, image):\n",
        "  # Compute the pixel coordiantes:\n",
        "  new_x = # ???\n",
        "  new_y = # ???\n",
        "\n",
        "  # Round to the nearest integer (important for later)\n",
        "  new_x = int(new_x)\n",
        "  new_y = int(new_y)\n",
        "\n",
        "  return (new_x, new_y)\n",
        "\n",
        "\n",
        "# Try using our new function to make sure it works:\n",
        "\n",
        "left_wrist = results.pose_landmarks.landmark[15]\n",
        "print(toPixelCoordinates(left_wrist.x, left_wrist.y, image))\n",
        "\n",
        "# This *should* print (1210, 951)"
      ],
      "metadata": {
        "id": "9d0NWYjYxsb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you get `(1210, 951)`. Once your function is working, you can use OpenCV to draw a circle on a particular landmark you're interested in. Edit the following code to draw the circle at the location of the left wrist. (Right now it just draws a circle at `(100, 100)`, which is not what we want.)"
      ],
      "metadata": {
        "id": "l60qKhUUzccR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image and convert to RGB format\n",
        "image = cv2.imread(\"tom-izzo.webp\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Compute the pose\n",
        "pose = mp.solutions.pose.Pose()\n",
        "results = pose.process(image)\n",
        "\n",
        "# Draw a circle on one particular landmark\n",
        "left_wrist = results.pose_landmarks.landmark[15]\n",
        "pixel_coords = toPixelCoordinates(left_wrist.x, left_wrist.y, image)\n",
        "print(\"Left wrist coordinates:\", pixel_coords)\n",
        "\n",
        "# THIS IS WRONG\n",
        "# Change it to print the circle in the correct location...\n",
        "cv2.circle(image, center=(100, 100), radius=50, color=(255, 0, 0), thickness=-1)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "VgIKDON3zpvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have the above code drawing a circle on the left wrist, try changing it to plot other landmarks. Can you give him a clown nose? (You can consult [the landmark map](https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png) to figure out which number to use.)\n",
        "\n",
        "Hopefully you can successfully plot any landmark!"
      ],
      "metadata": {
        "id": "ss29inbP0QO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Begin building a game\n",
        "So far we've been hanging out in this python notebook, and it has been a good time. But, like a bird learning to fly, it's time to leave the nest and make something real.\n",
        "\n",
        "<center>\n",
        "<img src=\"http://blogs.bu.edu/bioaerial2012/files/2012/10/Baby-Bird-Learning-to-Fly1.jpg\" alt=\"Mother bird agressively yeets baby out of the nest\" width=\"200\" />\n",
        "</center>\n",
        "\n",
        "This is necessary because we want to use the webcam at a high framerate, and that can only happen by running directly on your own machine, not in Google Colab.\n",
        "\n",
        "So your job is to create a python file on your computer and copy + paste in the following code. (If you need help with this, consult the FAQ page.)\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "def toPixelCoordinates(x, y, image):\n",
        "  # FILL THIS IN!\n",
        "  # ??????\n",
        "  return (new_x, new_y)\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "with mp.solutions.pose.Pose() as pose:\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            print(\"Ignoring empty camera frame.\")\n",
        "            continue\n",
        "\n",
        "        # Convert the image from BGR to RGB format:\n",
        "        image = # ???\n",
        "\n",
        "        # Flip the image horizontally:\n",
        "        # (Without this, the game is very confusing to play.)\n",
        "        image = cv2.flip(image, 1)\n",
        "\n",
        "        # Compute the pose results:\n",
        "        # (Note that the `pose` variable already exists.)\n",
        "        results = # ???\n",
        "\n",
        "        # Convert the image back to BGR format:\n",
        "        image = # ???\n",
        "\n",
        "        # Draw the pose annotation on the image.\n",
        "        mp.solutions.drawing_utils.draw_landmarks(\n",
        "            # ?????\n",
        "        )\n",
        "\n",
        "        # Highlight the wrists\n",
        "        # Left wrist\n",
        "        left_wrist = results.pose_landmarks.landmark[15]\n",
        "        left_point = toPixelCoordinates(left_wrist.x, left_wrist.y, image)\n",
        "        cv2.circle(image, center=left_point, radius=50, color=(255, 0, 0), thickness=-1)\n",
        "\n",
        "        # Right wrist\n",
        "        right_wrist = # ???\n",
        "        right_point = # ???\n",
        "        cv2.circle() # ???\n",
        "\n",
        "        # Display the image:\n",
        "        cv2.imshow(\"Game\", image)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Press \"q\" to quit.\n",
        "            break\n",
        "\n",
        "cap.release()\n",
        "```\n",
        "\n",
        "Notice that the code contains a few missing pieces, indicated by question marks (`???`). Using what you've learned from the notebook, you should be able to fill them in.\n",
        "\n",
        "Once you fill in all the gaps, you should have a program that displays your webcam on screen and highlights your wrists with circles."
      ],
      "metadata": {
        "id": "2JBJ29vD3JzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Add targets to hit\n",
        "\n",
        "Just detecting your hand motion is nice, but it isn't really a *game*. Let's add a goal by creating targets for the player to hit.\n",
        "\n",
        "First, copy + paste the following code into your python file near the top, just below all the imports:\n",
        "\n",
        "```python\n",
        "from random import random\n",
        "\n",
        "\n",
        "class Target:\n",
        "    def __init__(self, image):\n",
        "        # Give this target a randomized x, y, and radius\n",
        "        self.radius = random() * 50 + 50\n",
        "        self.x = random() * image.shape[1]\n",
        "        self.y = random() * image.shape[0]\n",
        "\n",
        "    def draw(self, image):\n",
        "        # Draw this target on the screen\n",
        "        cv2.circle(image, (int(self.x), int(self.y)),\n",
        "                   int(self.radius), (255, 0, 0), -1)\n",
        "\n",
        "    def point_is_within_me(self, x, y):\n",
        "        # Use the distance formula to determine if the point is within the circle\n",
        "        return (x - self.x) ** 2 + (y - self.y) ** 2 < self.radius ** 2\n",
        "\n",
        "    def hit_by_points(self, points):\n",
        "        for point in points:\n",
        "            if self.point_is_within_me(point[0], point[1]):\n",
        "                return True\n",
        "        return False\n",
        "```\n",
        "\n",
        "This code creates a new `Target` class that allows us to add new targets any time we want.\n",
        "\n",
        "Then, add `targets = []` before the main program loop to create an empty list of targets to hit.\n",
        "\n",
        "Next, immediately after the code that converts the image back from RGB to BGR, add the following loops to display the targets and make sure there are always at least 5 of them on screen:\n",
        "\n",
        "```python\n",
        "# Make sure there are at least 5 targets:\n",
        "while len(targets) < 5:\n",
        "    targets.append(Target(image))\n",
        "\n",
        "# Display the targets:\n",
        "for target in targets:\n",
        "    target.draw(image)\n",
        "```\n",
        "\n",
        "Now when you run the code, you should see 5 targets on screen. But how can we allow you to hit them?\n",
        "\n",
        "This is where the pose detection comes in. In the code that highlights the wrists with circles, we already have `left_point` and `right_point`, the coordinates of the wrists in the image. After that wrist highlighting code, add this loop which checks each target to see if it is currently being hit by a wrist:\n",
        "\n",
        "```python\n",
        "# Delete targets that were hit:\n",
        "for target in targets:\n",
        "    if target.hit_by_points([left_point, right_point]):\n",
        "        targets.remove(target)\n",
        "```\n",
        "\n",
        "Once that's done, you'll be able to play the game!"
      ],
      "metadata": {
        "id": "LewHoXm9F00X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Upgrade the game\n",
        "\n",
        "Now we have a working game! From here on, we just want to make upgrades that make it more fun.\n",
        "\n",
        "## Upgrade 1: Keep track of points\n",
        "Try creating a \"points\" variable to track how many targets you've hit. Display your score on-screen using OpenCV. (Refer to [last week's OpenCV workshop](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9) if needed, or use Google for help with drawing text on screen.)\n",
        "\n",
        "## Upgrade 2: Play with your feet\n",
        "Right now the game is played using your hands, by tracking the location of your wrists. Try changing the game to be played with your feet instead!\n",
        "\n",
        "## Upgrade 3 (challenge): Set a time limit\n",
        "Try adding a time limit to the game! When time runs out, the game should stop.\n",
        "\n",
        "## Upgrade 4 (challenge): Create moving targets\n",
        "Right now, the targets appear but they never move. Consider making moving targets instead!\n",
        "\n",
        "You might find it helpful to add `self.vel_x` and `self.vel_y` variables to the target so that you can keep track of its velocity in the x and y directions. Then, each frame, create a method on the target that updates the x and y positions accordingly:\n",
        "```python\n",
        "self.x += self.vel_x\n",
        "self.y += self.vel_y\n",
        "```\n",
        "\n",
        "## Upgrade 5 (challenge): Add sound effects\n",
        "Every game is better with sound."
      ],
      "metadata": {
        "id": "5ZlzK9RfOmV2"
      }
    }
  ]
}