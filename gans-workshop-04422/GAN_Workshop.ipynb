{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN Workshop",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This workshop is adapted from an original resource available [here](https://realpython.com/generative-adversarial-networks/). Many thanks to the original authors!"
      ],
      "metadata": {
        "id": "Cp4yYNU5Mjcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Generate Training Data"
      ],
      "metadata": {
        "id": "UFHEq_pX9y_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GANs are amazing. They can produce stunning art, realistic photographs, and 3D objects. Generally GANs are used for visual tasks like generating images, but in principle they can be used for much more.\n",
        "\n",
        "Fundamentally, GANs just look at example data and try to generate new data that looks the same. So when you have a set of example data points, you can use a GAN to create more.\n",
        "\n",
        "---\n",
        "\n",
        "Training a GAN takes a long time, so it will be impossible to train an image-generating GAN during this workshop. (Although there is some code at the bottom of this notebook that trains the computer to draw the digits 0-9. It takes about half an hour to start getting interesting results, so it's an excellent thing to try on your own time.)\n",
        "\n",
        "Instead, our simple GAN will generate points in 2D space that fall on a sine wave. Essentially, this means that our GAN is going to \"learn\" the sine function. By the time we're done, you will be able to feed it random input points and it will spit out points that are on the sine curve.\n",
        "\n",
        "Is it the most riveting example ever? Perhaps not. But it demonstrates all the basic tools you need to create GANs that solve more complex problems; the only additional ingredient you need on top of what we're doing today is more training time.\n",
        "\n",
        "---\n",
        "\n",
        "Before doing anything else, let's import the libraries we need so that we have them from now on. Run the following code without changing anything:"
      ],
      "metadata": {
        "id": "WIvXsWLm9gip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8vMymdiK0fY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So how do we generate our training data? We want to create a big list of 2D points $(x, y)$ which are all on the sine wave. Let's start by making a list of points that are all $(0, 0)$ and go from there.\n",
        "\n",
        "The following code generates a list of four zero points. Can you change it to generate a list of 1024 points?"
      ],
      "metadata": {
        "id": "9Qh7W6qcV78M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE ME! I need to generate 1024 points, not 4.\n",
        "\n",
        "train_data_length = 4\n",
        "train_data = torch.zeros((train_data_length, 2))\n",
        "\n",
        "print(\"Training data:\")\n",
        "print(train_data)\n",
        "\n",
        "print(\"Number of points:\", len(train_data))"
      ],
      "metadata": {
        "id": "QgvT5Tai7NS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good start. But of course, the points shouldn't all be $(0, 0)$. We want our points to be randomly distributed between $x = 0$ and $x = 2\\pi$.\n",
        "\n",
        "The following code generates a list of 1024 different numbers between 0 and 1:"
      ],
      "metadata": {
        "id": "I8SSl_tdDUQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(train_data_length)"
      ],
      "metadata": {
        "id": "fTsekNt3D59X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this code generates 1024 different numbers between $0$ and $\\pi$:"
      ],
      "metadata": {
        "id": "b38_BZToD9zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "math.pi * torch.rand(train_data_length)"
      ],
      "metadata": {
        "id": "njsBF29lEEQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you write code that generates 1024 different numbers between $0$ and $2\\pi$?"
      ],
      "metadata": {
        "id": "4_LuZvEREJOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Generate 1024 numbers between 0 and 2*pi"
      ],
      "metadata": {
        "id": "kHe6oeMoENPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazing! Now... remember `train_data`, our list of points that are all $(0, 0)$? Let's update that list by replacing all the x values with our new list of random numbers.\n",
        "\n",
        "Replace the `# ???` in the following code with your generation code (from $0$ to $2\\pi$) from above.\n",
        "\n",
        "If all goes well, you should see that the x values have been randomized but the y values are still 0."
      ],
      "metadata": {
        "id": "Fm0DgCRfEQ-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the x values of the train_data points to be random\n",
        "train_data[:, 0] = # ???\n",
        "\n",
        "print(train_data)"
      ],
      "metadata": {
        "id": "1tc2MsM7CKbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's graph a scatterplot of the points to see if they look right:"
      ],
      "metadata": {
        "id": "exWXOTIXE24T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
      ],
      "metadata": {
        "id": "gODkQImNEdDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool! You should see a horizontal line from $x = 0$ to $x = 2\\pi \\approx 6.28$.\n",
        "\n",
        "Now we just need to set the y values. The following code will set the y values to be the cosine of each x value.\n",
        "\n",
        "Can you change it to `sin`?"
      ],
      "metadata": {
        "id": "4barDymtE6df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code sets the y values to cos(x). Can you change it to sin(x)?\n",
        "train_data[:, 1] = torch.cos(train_data[:, 0])\n",
        "\n",
        "print(train_data)"
      ],
      "metadata": {
        "id": "buqAXCGoEecQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check your results, and make sure it looks like a sine wave (not cosine):"
      ],
      "metadata": {
        "id": "jxn5iV3ZFUMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
      ],
      "metadata": {
        "id": "ekiNTkW7FXtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazing! This will be our training data for the GAN. The GAN's job will be to take in random points as creative fuel, and spit out points that are on this sine wave. Hopefully it can learn this task!"
      ],
      "metadata": {
        "id": "L5sWCqLeFew9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Train on Sine Wave"
      ],
      "metadata": {
        "id": "DX3MPnhBFutv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every GAN is made up of two competing neural networks: The generator and the discriminator. To keep things (relatively) simple, we aren't going to go into great detail about how these networks work, and I'm not going to ask you to design them yourself.\n",
        "\n",
        "Just know that the following code creates two models, `generator` and `discriminator`, each of which is a simple neural network to learn its respective task.\n",
        "\n",
        "(You do not need to change this code at all; just run it.)"
      ],
      "metadata": {
        "id": "Pa2XHakCRgdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the generator\n",
        "# (Note that the definition inside __init__ begins with a 2 and ends with a 2,\n",
        "# so the model takes a 2D point as input and gives a 2D point as output.)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16), # Take 2D point as input...\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2), # ...and give 2D point as output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "generator = Generator()"
      ],
      "metadata": {
        "id": "7ElmX7tKMDWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the discriminator\n",
        "# (Note that the definition inside __init__ begins with a 2 and ends with a 1,\n",
        "# so the model takes a 2D point as input and gives one number--the prediction for\n",
        "# whether or not the point is real--as output.)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 256), # Take 2D point as input...\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1), # ...and give one number as output\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "3tslA8PPLo79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A slow-motion step\n",
        "\n",
        "During the presentation, we created this diagram of a single training step for a GAN:\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://i.imgur.com/iud7C21.png\" alt=\"GAN Diagram\" width=\"500\" />\n",
        "</center>\n",
        "\n",
        "Eventually, we want to write code that performs this entire process many, many times inside a `for` loop. But let's start by walking through each part of the process one bit at a time. (We'll put it all together at the end.)\n",
        "\n",
        "---\n",
        "\n",
        "To start, let's generate some \"latent space\" samples. In our diagram, these look like TV static:\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://i.imgur.com/7pdjDyX.png\" alt=\"GAN Diagram with latent space labels highlighted\" width=\"400\" />\n",
        "</center>\n",
        "\n",
        "They are essentially just random input values (which is why it looks like TV static for a GAN that generates images). In our case, a random input value is just a random point in 2D space (which is not necessarily on the sine wave). We can generate these using the `torch.randn()` function, which genreates an array of random values with a given shape.\n",
        "\n",
        "The following code generates a batch of `5` random `2`-dimensional points. Try changing the code to make `batch_size` be 32 instead, and check to see that 32 points appear."
      ],
      "metadata": {
        "id": "5gxDseftMHGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Change `batch_size` from 5 to 32\n",
        "batch_size = 5\n",
        "\n",
        "# Generate latent space samples\n",
        "latent_space_samples = torch.randn((batch_size, 2))\n",
        "\n",
        "# Plot the points\n",
        "plt.plot(latent_space_samples[:, 0], latent_space_samples[:, 1], \".\")"
      ],
      "metadata": {
        "id": "f9ejrMfJcEaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now let's take our `latent_space_samples` and pass them through the `generator` to get the `generated_samples`.\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://i.imgur.com/T28WLV2.png\" alt=\"GAN Diagram with generator process highlighted\" width=\"400\" />\n",
        "</center>\n",
        "\n",
        "The following code does just that:"
      ],
      "metadata": {
        "id": "R1iQ4YYnOF9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the `generator` to get `generated_samples` from `latent_space_samples`\n",
        "generated_samples = generator(latent_space_samples)\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(generated_samples.detach()[:, 0], generated_samples.detach()[:, 1], \".\")"
      ],
      "metadata": {
        "id": "fwaE5K8mOUHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, the points being produced just look like new random garbage. But as the generator trains and improves, it will start to produce points that actually land on the sine wave.\n",
        "\n",
        "---\n",
        "\n",
        "Next, we want to grab a batch of real samples from the original dataset of sine wave points we created in step 1.\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://i.imgur.com/r2OIQLt.png\" alt=\"GAN Diagram with real sampling highlighted\" width=\"400\" />\n",
        "</center>\n",
        "\n",
        "The pytorch library gives us a useful tool called a `DataLoader` that will do this for us. The following code creates a `DataLoader` called `train_loader` (because it loads the training examples). Then we can use a `for` loop to loop through each batch it gives us.\n",
        "\n",
        "Edit the following code so that inside the `for` loop it prints out some useful information. (Your goal is to understand what `index` and `real_samples` are.)"
      ],
      "metadata": {
        "id": "LsCTQBmSO_2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader called `train_loader` that will give us batches of real samples\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  train_data, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "# Then we can iterate through the batches using a `for` loop:\n",
        "for index, real_samples in enumerate(train_loader):\n",
        "  # TODO: Print out some useful information. Try printing the index and real_samples"
      ],
      "metadata": {
        "id": "2m74ssiQQCuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the ability to get `generated_samples` and `real_samples`, it's time to put the `descriminator` to work:\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://i.imgur.com/f2KA7AB.png\" alt=\"GAN Diagram with discriminator highlighted\" width=\"400\" />\n",
        "</center>"
      ],
      "metadata": {
        "id": "tdEMCqfQQ2Ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's combine `real_samples` (a list of 32 points in 2D space) and `generated_samples` (another list of 32 points in 2D space) into one big list called `all_samples`. This will be what we give the discriminator as a test.\n",
        "\n",
        "We'll use the `torch.cat()` concatenation function to combine the lists:"
      ],
      "metadata": {
        "id": "yi4Nol1Syibl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show that `real_samples` and `generated_samples` are both lists of 32 points in 2D space:\n",
        "print(\"Shape of real samples:\", real_samples.shape)\n",
        "print(\"Shape of generated samples:\", generated_samples.shape)\n",
        "\n",
        "# Then merge the two into one big list of samples...\n",
        "all_samples = torch.cat((real_samples, generated_samples))\n",
        "\n",
        "# ...and check that the combined list has 64 points in 2D space:\n",
        "print(\"Shape of ALL samples (combined):\", all_samples.shape)"
      ],
      "metadata": {
        "id": "kc5hK32SwkzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our test questions, we can ask the descriminator to give us its report:"
      ],
      "metadata": {
        "id": "fv4Mr8NAzJIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_result = discriminator(all_samples)\n",
        "\n",
        "print(discriminator_result)"
      ],
      "metadata": {
        "id": "s1FQRPsHy-r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the output is a big list of 64 numbers. Each number corresponds to one of the samples from `all_samples`, the \"test\" we gave the discriminator. Each number is the probability the descriminator thinks each sample has of being real.\n",
        "\n",
        "**What do you notice about the probabilities?**\n",
        "\n",
        "Most likely, they will all be around 50%. That's because the discriminator hasn't learned anything yet, so it is basically just guessing. Over time, the discriminator will improve. (Although the generator will also get better at being tricky; it's a bit of an arms race.)\n",
        "\n",
        "---\n",
        "\n",
        "Finally, we need to build an \"answer key\" to the test, so that the discriminator and generator can both look at the results and improve themselves during backpropagation.\n",
        "\n",
        "In machine learning lingo, this answer key is called the \"labels\" of the dataset, because we're labelling each of the samples with whether it is actually real or generated.\n",
        "\n",
        "The following code should create `real_samples_labels`, which is a list of ones (because the label 1 means \"real\") and `generated_samples_labels` which is a list of zeros (because the label 0 means \"generated\"). Then they can be combined to give `all_samples_labels`, our answer key to the overall test.\n",
        "\n",
        "You will need to modify the code below to do just that:"
      ],
      "metadata": {
        "id": "Xhwl9H0gz7Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create `real_samples_labels`, a list of 32 ones:\n",
        "real_samples_labels = torch.ones((batch_size, 1))\n",
        "\n",
        "# TODO: Use the function torch.zeros(), which is just like torch.ones(),\n",
        "# to create `generated_samples_labels`:\n",
        "generated_samples_labels = # ???\n",
        "\n",
        "# TODO: Combine `real_samples_labels` and `generated_samples_labels` into a single list\n",
        "# called `all_samples_labels` using the function torch.cat() in the exact same way as\n",
        "# we used it before to combine `real_samples` and `generated_samples`\n",
        "all_samples_labels = # ???\n",
        "\n",
        "print(all_samples_labels)"
      ],
      "metadata": {
        "id": "kYhoIZDG2Wb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazing! Hopefully you see a list with a bunch of 1s and then a bunch of 0s. If so, you've made the answer key (`all_samples_labels`) correctly."
      ],
      "metadata": {
        "id": "Vho1U4Tg_ZcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actual Training\n",
        "At this point, you've performed all the individual processes that go into one training step. Now it's just a matter of putting it all together.\n",
        "\n",
        "The following code, when completed, will run 300 \"epochs\" of training (which means running the training process on the entire dataset 300 times).\n",
        "\n",
        "Your job is to fill in the missing blanks, indicated by `# ???`, by copying the code you wrote above. Once you've done that, you should be able to run this entire massive code block and watch the generator and discriminator learn."
      ],
      "metadata": {
        "id": "160JwgUR_iun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_of_results = []\n",
        "\n",
        "lr = 0.001 # learning rate\n",
        "loss_function = nn.BCELoss() # binary cross-entropy loss function\n",
        "\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(300):\n",
        "  # This loop gets batches of `real_samples` from the training dataset\n",
        "  for n, real_samples in enumerate(train_loader):\n",
        "    # Get `generated_samples` by plugging latent space samples (TV static) into the generator\n",
        "    latent_space_samples = # ???\n",
        "    generated_samples = # ???\n",
        "\n",
        "    # Combine `real_samples` and `generated_samples` into one list\n",
        "    all_samples = # ???\n",
        "\n",
        "    # Create labels (the \"answer key\") for the data\n",
        "    real_samples_labels = # ???\n",
        "    generated_samples_labels = # ???\n",
        "    all_samples_labels = # ???\n",
        "\n",
        "    # Train the discriminator\n",
        "    discriminator.zero_grad()\n",
        "    discriminator_result = # ???\n",
        "    loss_discriminator = loss_function(discriminator_result, all_samples_labels)\n",
        "    loss_discriminator.backward(retain_graph=True)\n",
        "    optimizer_discriminator.step()\n",
        "\n",
        "    # Train the generator\n",
        "    generator.zero_grad()\n",
        "    output_discriminator_generated = discriminator(generated_samples)\n",
        "    loss_generator = loss_function(\n",
        "      output_discriminator_generated, real_samples_labels # optimize for tricking the descriminator into thinking these are real samples\n",
        "    )\n",
        "    loss_generator.backward()\n",
        "    optimizer_generator.step()\n",
        "\n",
        "  # Show loss once every 10 epochs\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
        "    print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")\n",
        "\n",
        "  # Save data to build a graph once every 50 epochs\n",
        "  if epoch % 50 == 0:\n",
        "    latent_space_samples = torch.randn(100, 2)\n",
        "    generated_samples = generator(latent_space_samples)\n",
        "    generated_samples = generated_samples.detach()\n",
        "    history_of_results.append(generated_samples)"
      ],
      "metadata": {
        "id": "pRjKpaKJM1Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the training is done, run the following code to visualize the generator output over the course of training (i.e. how it learned over time):"
      ],
      "metadata": {
        "id": "AZkOwBpGCqxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "\n",
        "f, axs = plt.subplots(1, len(history_of_results))\n",
        "\n",
        "for i, generated_samples in enumerate(history_of_results):\n",
        "  axs[i].set_title(\"Epoch {}\".format((i + 1) * 50))\n",
        "  axs[i].plot(history_of_results[i][:, 0], history_of_results[i][:, 1], \".\")\n",
        "\n",
        "f.set_size_inches(24, 3)"
      ],
      "metadata": {
        "id": "nFVuL-suOI1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully, you will se that in the beginning (epoch 50), the generator was really bad and basically just smeared the points out on the screen. But by the end, it should be arranging the points into a sine wave.\n",
        "\n",
        "You can run this code to give the generator one final test, and make sure it arranges points correctly:"
      ],
      "metadata": {
        "id": "gYEJl54aC2Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final test of generator\n",
        "latent_space_samples = torch.randn(100, 2)\n",
        "generated_samples = generator(latent_space_samples)\n",
        "generated_samples = generated_samples.detach()\n",
        "plt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")"
      ],
      "metadata": {
        "id": "pLsJQNuXNJn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, as a little curiosity, you can check out what the discriminator has learned. Hopefully it can successfully identify where the sine wave is and is not:"
      ],
      "metadata": {
        "id": "Qe-kht2eDEgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final test of discriminator\n",
        "xs = torch.linspace(0, 2 * math.pi, steps=314)\n",
        "ys = torch.linspace(-1, 1, steps=100)\n",
        "x, y = torch.meshgrid(xs, ys, indexing='xy')\n",
        "z = discriminator(torch.stack((x.flatten(), y.flatten()), 1))\n",
        "Z = z.reshape((100, 314))\n",
        "\n",
        "plt.imshow(Z.detach(), interpolation='bilinear', origin='lower', extent=[0,2*math.pi,-1,1])"
      ],
      "metadata": {
        "id": "G3f3PXnHGqGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually it will be very good on the left and a little messy on the right. With more training time, this would slowly improve.\n",
        "\n",
        "---\n",
        "\n",
        "You have now successfully trained a GAN! If you want something fun to do during the workshop, you can try going back to step 1 and generating training data for some new curve (maybe cosine, or some fun polynomial). Then re-run the training process and see if the GAN can learn to produce points on that new curve.\n",
        "\n",
        "---\n",
        "\n",
        "And, if you have time to run code at home, you can try out the code below. It isn't commented, but it does essentially the exact same thing as the code above. The only difference is that it learns to produce handwritten digit images rather than sine wave points.\n",
        "\n",
        "Here is a GIF showing what that result will look like:\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://files.realpython.com/media/fig_gan_mnist.5d8784a85944.gif\" alt=\"GAN digit training result over time\" width=\"500\" />\n",
        "</center>"
      ],
      "metadata": {
        "id": "jA8IQzajDNRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 (Take-Home Bonus): ~Hand~written Digits"
      ],
      "metadata": {
        "id": "gyqIrckeRebu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "nmvlyj4xRlsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"\"\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xX09cW0dRosQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")"
      ],
      "metadata": {
        "id": "TGnDJWstRtFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.MNIST(\n",
        "    root=\".\", train=True, download=True, transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "Fv-cvBEdRvKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "uuQRAUtbRzyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_samples, mnist_labels = next(iter(train_loader))\n",
        "for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "metadata": {
        "id": "Nr3LTT_OR19N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), 784)\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "discriminator = Discriminator().to(device=device)"
      ],
      "metadata": {
        "id": "HyQxRa0kR-eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        output = output.view(x.size(0), 1, 28, 28)\n",
        "        return output\n",
        "\n",
        "generator = Generator().to(device=device)"
      ],
      "metadata": {
        "id": "jW-kZGvSSDpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "num_epochs = 20\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "1HVuk15YSDkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next code is the big training step. It will take a long time... (It ends after 20 epochs.)"
      ],
      "metadata": {
        "id": "oR2bwUFuS6lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for n, (real_samples, mnist_labels) in enumerate(train_loader):\n",
        "        # Data for training the discriminator\n",
        "        real_samples = real_samples.to(device=device)\n",
        "        real_samples_labels = torch.ones((batch_size, 1)).to(\n",
        "            device=device\n",
        "        )\n",
        "        latent_space_samples = torch.randn((batch_size, 100)).to(\n",
        "            device=device\n",
        "        )\n",
        "        generated_samples = generator(latent_space_samples)\n",
        "        generated_samples_labels = torch.zeros((batch_size, 1)).to(\n",
        "            device=device\n",
        "        )\n",
        "        all_samples = torch.cat((real_samples, generated_samples))\n",
        "        all_samples_labels = torch.cat(\n",
        "            (real_samples_labels, generated_samples_labels)\n",
        "        )\n",
        "\n",
        "        # Training the discriminator\n",
        "        discriminator.zero_grad()\n",
        "        output_discriminator = discriminator(all_samples)\n",
        "        loss_discriminator = loss_function(\n",
        "            output_discriminator, all_samples_labels\n",
        "        )\n",
        "        loss_discriminator.backward()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "        # Data for training the generator\n",
        "        latent_space_samples = torch.randn((batch_size, 100)).to(\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Training the generator\n",
        "        generator.zero_grad()\n",
        "        generated_samples = generator(latent_space_samples)\n",
        "        output_discriminator_generated = discriminator(generated_samples)\n",
        "        loss_generator = loss_function(\n",
        "            output_discriminator_generated, real_samples_labels\n",
        "        )\n",
        "        loss_generator.backward()\n",
        "        optimizer_generator.step()\n",
        "\n",
        "        # Show loss\n",
        "        if n == batch_size - 1:\n",
        "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
        "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
      ],
      "metadata": {
        "id": "EYyvS9nYSJ-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(discriminator.state_dict(), \"discriminator\")\n",
        "torch.save(generator.state_dict(), \"generator\")"
      ],
      "metadata": {
        "id": "SY_-g-vcYCag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_space_samples = torch.randn(batch_size, 100).to(device=device)\n",
        "generated_samples = generator(latent_space_samples)"
      ],
      "metadata": {
        "id": "kThVKIlVSQRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_samples = generated_samples.cpu().detach()\n",
        "for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "metadata": {
        "id": "QScSmNFpSR_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}